"""
FBref.com ë°ì´í„° ìŠ¤í¬ë˜í¼
EPL ê²½ê¸° ì¼ì •, ê²°ê³¼, íŒ€ í†µê³„ ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FBrefScraper:
    def __init__(self):
        self.base_url = "https://fbref.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        # Rate limiting
        self.request_delay = 3  # seconds

    def get_epl_fixtures(self, season="2024-2025", use_cache=True):
        """
        EPL ê²½ê¸° ì¼ì • ê°€ì ¸ì˜¤ê¸°

        Args:
            season: ì‹œì¦Œ (ì˜ˆ: "2024-2025")
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€

        Returns:
            DataFrame: ê²½ê¸° ì¼ì • ë°ì´í„°
        """
        logger.info(f"Fetching EPL fixtures for season {season}")

        # FBref EPL URL
        url = f"{self.base_url}/en/comps/9/schedule/Premier-League-Scores-and-Fixtures"

        try:
            time.sleep(self.request_delay)
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'lxml')

            # ê²½ê¸° ì¼ì • í…Œì´ë¸” ì°¾ê¸° (ì—¬ëŸ¬ ID ì‹œë„)
            fixtures_table = None
            possible_ids = [f'sched_{season}_9_1', 'sched_all']

            for table_id in possible_ids:
                fixtures_table = soup.find('table', {'id': table_id})
                if fixtures_table:
                    break

            # classë¡œë„ ì‹œë„
            if not fixtures_table:
                fixtures_table = soup.find('table', class_='stats_table')

            if not fixtures_table:
                logger.warning("Fixtures table not found, using dummy data")
                return self._get_dummy_fixtures()

            # í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ë³€í™˜
            df = pd.read_html(str(fixtures_table))[0]

            # ì»¬ëŸ¼ ì •ë¦¬
            df = self._clean_fixtures_dataframe(df)

            # ë¹ˆ í–‰ ì œê±°
            df = df.dropna(subset=['home_team', 'away_team'], how='all')

            # í–¥í›„ ê²½ê¸°ë§Œ í•„í„°ë§ (Scoreê°€ ë¹„ì–´ìˆëŠ” ê²½ê¸°)
            if 'score' in df.columns:
                # Scoreê°€ NaNì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ê¸°ë§Œ
                df = df[df['score'].isna() | (df['score'] == '')]
                logger.info(f"Filtered to {len(df)} upcoming fixtures")

            # ë‚ ì§œë¡œ ì •ë ¬
            if 'date' in df.columns:
                try:
                    df = df.sort_values('date')
                except:
                    pass

            # ìµœëŒ€ 20ê²½ê¸°ë¡œ ì œí•œ
            df = df.head(20)

            logger.info(f"Returning {len(df)} fixtures")
            return df

        except requests.RequestException as e:
            logger.error(f"Network error fetching fixtures: {e}")
            return self._get_dummy_fixtures()
        except Exception as e:
            logger.error(f"Error fetching fixtures: {e}")
            return self._get_dummy_fixtures()

    def get_team_stats(self, season="2024-2025"):
        """
        íŒ€ í†µê³„ ê°€ì ¸ì˜¤ê¸°

        Returns:
            DataFrame: íŒ€ í†µê³„ ë°ì´í„°
        """
        logger.info(f"Fetching team stats for season {season}")

        url = f"{self.base_url}/en/comps/9/Premier-League-Stats"

        try:
            time.sleep(self.request_delay)
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'lxml')

            # íŒ€ í†µê³„ í…Œì´ë¸”
            stats_table = soup.find('table', {'id': 'stats_squads_standard_for'})

            if not stats_table:
                logger.warning("Stats table not found")
                return self._get_dummy_team_stats()

            df = pd.read_html(str(stats_table))[0]
            df = self._clean_team_stats_dataframe(df)

            logger.info(f"Found stats for {len(df)} teams")
            return df

        except Exception as e:
            logger.error(f"Error fetching team stats: {e}")
            return self._get_dummy_team_stats()

    def _clean_fixtures_dataframe(self, df):
        """ê²½ê¸° ì¼ì • DataFrame ì •ë¦¬"""
        # ì»¬ëŸ¼ëª… ì •ë¦¬ (ì‹¤ì œ FBref êµ¬ì¡°ì— ë§ì¶° ì¡°ì • í•„ìš”)
        column_mapping = {
            'Wk': 'gameweek',
            'Date': 'date',
            'Home': 'home_team',
            'Away': 'away_team',
            'Score': 'score',
            'xG': 'home_xg',
            'xG.1': 'away_xg'
        }

        # ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ë§¤í•‘
        for old_col, new_col in column_mapping.items():
            if old_col in df.columns:
                df.rename(columns={old_col: new_col}, inplace=True)

        return df

    def _clean_team_stats_dataframe(self, df):
        """íŒ€ í†µê³„ DataFrame ì •ë¦¬"""
        # Multi-level ì»¬ëŸ¼ ì²˜ë¦¬
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = ['_'.join(col).strip() for col in df.columns.values]

        return df

    def _get_dummy_fixtures(self):
        """ë”ë¯¸ ê²½ê¸° ì¼ì • ë°ì´í„°"""
        return pd.DataFrame({
            'gameweek': [8, 8, 8, 8, 8],
            'date': ['2024-10-05', '2024-10-05', '2024-10-05', '2024-10-06', '2024-10-06'],
            'home_team': ['Manchester City', 'Arsenal', 'Tottenham', 'Newcastle', 'Aston Villa'],
            'away_team': ['Liverpool', 'Chelsea', 'Manchester United', 'Brighton', 'Wolves'],
            'home_score': [None, None, None, None, None],
            'away_score': [None, None, None, None, None],
            'home_xg': [None, None, None, None, None],
            'away_xg': [None, None, None, None, None],
            'status': ['scheduled', 'scheduled', 'scheduled', 'scheduled', 'scheduled']
        })

    def _get_dummy_team_stats(self):
        """ë”ë¯¸ íŒ€ í†µê³„ ë°ì´í„°"""
        teams = ['Manchester City', 'Arsenal', 'Liverpool', 'Tottenham', 'Chelsea',
                 'Manchester United', 'Newcastle', 'Brighton', 'Aston Villa', 'Wolves']

        return pd.DataFrame({
            'team': teams,
            'matches_played': [7] * 10,
            'wins': [5, 5, 4, 4, 4, 3, 3, 3, 3, 2],
            'draws': [2, 1, 2, 2, 1, 2, 2, 2, 1, 3],
            'losses': [0, 1, 1, 1, 2, 2, 2, 2, 3, 2],
            'goals_for': [18, 16, 14, 15, 13, 10, 11, 10, 9, 8],
            'goals_against': [5, 7, 8, 8, 10, 9, 10, 9, 11, 10],
            'points': [17, 16, 14, 14, 13, 11, 11, 11, 10, 9]
        })

    def get_league_standings(self, season="2024-2025"):
        """
        í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ ìˆœìœ„í‘œ ê°€ì ¸ì˜¤ê¸°

        Args:
            season: ì‹œì¦Œ (ì˜ˆ: "2024-2025")

        Returns:
            DataFrame: ìˆœìœ„í‘œ ë°ì´í„°
        """
        logger.info(f"Fetching EPL standings for season {season}")

        # í˜„ì¬ ì‹œì¦Œ í˜ì´ì§€ URL (ë¦¬ê·¸ í…Œì´ë¸” í¬í•¨)
        url = f"{self.base_url}/en/comps/9/Premier-League-Stats"

        try:
            time.sleep(self.request_delay)
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'lxml')

            # Premier League ìˆœìœ„í‘œ í…Œì´ë¸” ì°¾ê¸°
            # FBrefëŠ” 'results' ì ‘ë‘ì‚¬ì™€ ì‹œì¦Œ ì½”ë“œë¥¼ ì‚¬ìš©
            standings_table = None

            # ë¨¼ì € classë¡œ ì°¾ê¸° (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
            all_tables = soup.find_all('table', class_='stats_table')

            for table in all_tables:
                caption = table.find('caption')
                if caption and 'League Table' in caption.text:
                    standings_table = table
                    logger.info("Found standings table by caption: League Table")
                    break

            # IDë¡œë„ ì‹œë„
            if not standings_table:
                season_id = season.replace('-', '')
                possible_table_ids = [
                    f'results{season_id}91_overall',
                    'results_overall',
                    'standings'
                ]

                for table_id in possible_table_ids:
                    standings_table = soup.find('table', {'id': table_id})
                    if standings_table:
                        logger.info(f"Found standings table with ID: {table_id}")
                        break

            if not standings_table:
                logger.warning("Standings table not found, using dummy data")
                return self._get_dummy_standings()

            # í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ë³€í™˜
            df = pd.read_html(str(standings_table))[0]

            # ì»¬ëŸ¼ ì •ë¦¬
            df = self._clean_standings_dataframe(df)

            logger.info(f"Found standings for {len(df)} teams")
            return df

        except requests.RequestException as e:
            logger.error(f"Network error fetching standings: {e}")
            return self._get_dummy_standings()
        except Exception as e:
            logger.error(f"Error fetching standings: {e}")
            return self._get_dummy_standings()

    def _clean_standings_dataframe(self, df):
        """ìˆœìœ„í‘œ DataFrame ì •ë¦¬"""
        # Multi-level ì»¬ëŸ¼ ì²˜ë¦¬
        if isinstance(df.columns, pd.MultiIndex):
            # ë§ˆì§€ë§‰ ë ˆë²¨ë§Œ ì‚¬ìš© (ê°€ì¥ êµ¬ì²´ì ì¸ ì»¬ëŸ¼ëª…)
            df.columns = [col[-1] if isinstance(col, tuple) else col for col in df.columns]

        # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (ì²« ë²ˆì§¸ ê²ƒë§Œ ìœ ì§€)
        df = df.loc[:, ~df.columns.duplicated()]

        # ì»¬ëŸ¼ëª… í‘œì¤€í™” ë§¤í•‘
        column_mapping = {
            'Squad': 'team',
            'MP': 'matches_played',
            'W': 'wins',
            'D': 'draws',
            'L': 'losses',
            'GF': 'goals_for',
            'GA': 'goals_against',
            'GD': 'goal_difference',
            'Pts': 'points',
            'Rk': 'rank'
        }

        # ì»¬ëŸ¼ëª… ë³€ê²½ (ë”•ì…”ë„ˆë¦¬ í•œë²ˆì— ì ìš©)
        rename_dict = {}
        for old_col in df.columns:
            for pattern, new_col in column_mapping.items():
                if pattern in str(old_col):
                    rename_dict[old_col] = new_col
                    break

        df = df.rename(columns=rename_dict)

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
        required_cols = ['team', 'matches_played', 'wins', 'draws', 'losses',
                        'goals_for', 'goals_against', 'points']

        for col in required_cols:
            if col not in df.columns:
                df[col] = 0

        # ë“ì‹¤ì°¨ ê³„ì‚° (ì—†ìœ¼ë©´)
        if 'goal_difference' not in df.columns:
            df['goal_difference'] = df['goals_for'] - df['goals_against']

        # ìˆœìœ„ ìƒì„± (ì—†ìœ¼ë©´)
        if 'rank' not in df.columns:
            df = df.sort_values('points', ascending=False).reset_index(drop=True)
            df['rank'] = range(1, len(df) + 1)

        return df

    def _get_dummy_standings(self):
        """ë”ë¯¸ ìˆœìœ„í‘œ ë°ì´í„°"""
        teams = [
            'Manchester City', 'Arsenal', 'Liverpool', 'Aston Villa', 'Tottenham',
            'Chelsea', 'Newcastle United', 'Manchester United', 'West Ham', 'Brighton',
            'Brentford', 'Fulham', 'Wolverhampton Wanderers', 'Crystal Palace', 'Everton',
            'Nottingham Forest', 'Bournemouth', 'Leicester', 'Ipswich', 'Southampton'
        ]

        # í˜„ì‹¤ì ì¸ ìˆœìœ„í‘œ ë°ì´í„° ìƒì„±
        standings_data = []
        for i, team in enumerate(teams):
            mp = 10
            # ìƒìœ„íŒ€ì¼ìˆ˜ë¡ ë†’ì€ ìŠ¹ì 
            if i < 4:  # ìƒìœ„ 4ê°œ íŒ€
                w, d, l = 7 + (4-i), 2, 1
            elif i < 10:  # ì¤‘ìœ„ê¶Œ
                w, d, l = 5, 3, 2
            elif i < 17:  # í•˜ìœ„ê¶Œ
                w, d, l = 3, 3, 4
            else:  # ê°•ë“±ê¶Œ
                w, d, l = 2, 2, 6

            gf = 20 - i
            ga = 8 + i
            pts = w * 3 + d

            standings_data.append({
                'rank': i + 1,
                'team': team,
                'matches_played': mp,
                'wins': w,
                'draws': d,
                'losses': l,
                'goals_for': gf,
                'goals_against': ga,
                'goal_difference': gf - ga,
                'points': pts
            })

        return pd.DataFrame(standings_data)

    def get_team_squad(self, team_name, season="2024-2025"):
        """
        íŠ¹ì • íŒ€ì˜ ì„ ìˆ˜ëª…ë‹¨ ê°€ì ¸ì˜¤ê¸°

        Args:
            team_name: íŒ€ ì´ë¦„
            season: ì‹œì¦Œ

        Returns:
            DataFrame: ì„ ìˆ˜ëª…ë‹¨ ë°ì´í„°
        """
        logger.info(f"Fetching squad for {team_name} ({season})")

        # FBref íŒ€ URL ë§¤í•‘ (ê°„ì†Œí™”ëœ ë²„ì „)
        team_url_map = {
            'Manchester City': 'b8fd03ef/Manchester-City',
            'Arsenal': '18bb7c10/Arsenal',
            'Liverpool': '822bd0ba/Liverpool',
            'Chelsea': 'cff3d9bb/Chelsea',
            'Manchester United': '19538871/Manchester-United',
            'Tottenham': '361ca564/Tottenham-Hotspur',
            'Newcastle United': 'b2b47a98/Newcastle-United',
            'Aston Villa': '8602292d/Aston-Villa',
            'Brighton': 'd07537b9/Brighton-and-Hove-Albion',
            'West Ham': '7c21e445/West-Ham-United'
        }

        team_url = team_url_map.get(team_name)
        if not team_url:
            logger.warning(f"No URL mapping for {team_name}, using dummy data")
            return self._get_dummy_squad(team_name)

        url = f"{self.base_url}/en/squads/{team_url}-Stats"

        try:
            time.sleep(self.request_delay)
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'lxml')

            # ì„ ìˆ˜ í†µê³„ í…Œì´ë¸” ì°¾ê¸°
            squad_table = soup.find('table', {'id': 'stats_standard_9'})

            if not squad_table:
                logger.warning(f"Squad table not found for {team_name}, using dummy data")
                return self._get_dummy_squad(team_name)

            df = pd.read_html(str(squad_table))[0]
            df = self._clean_squad_dataframe(df, team_name)

            logger.info(f"Found {len(df)} players for {team_name}")
            return df

        except requests.RequestException as e:
            logger.error(f"Network error fetching squad: {e}")
            return self._get_dummy_squad(team_name)
        except Exception as e:
            logger.error(f"Error fetching squad: {e}")
            return self._get_dummy_squad(team_name)

    def _clean_squad_dataframe(self, df, team_name):
        """ì„ ìˆ˜ëª…ë‹¨ DataFrame ì •ë¦¬"""
        # Multi-level ì»¬ëŸ¼ ì²˜ë¦¬
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = ['_'.join(str(col).strip() for col in cols if col) for cols in df.columns.values]

        # í•„ìš”í•œ ì»¬ëŸ¼ ì¶”ì¶œ ë° ì´ë¦„ ë³€ê²½
        column_mapping = {
            'Player': 'name',
            'Nation': 'nationality',
            'Pos': 'position',
            'Age': 'age',
            '#': 'number'
        }

        # ì»¬ëŸ¼ ë§¤í•‘
        for old_col in df.columns:
            for pattern, new_col in column_mapping.items():
                if pattern in old_col:
                    df.rename(columns={old_col: new_col}, inplace=True)
                    break

        # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°
        required_cols = ['name', 'position', 'age', 'nationality']
        available_cols = [col for col in required_cols if col in df.columns]

        if not available_cols:
            return pd.DataFrame()

        df = df[available_cols].copy()

        # ë°ì´í„° ì •ì œ
        if 'nationality' in df.columns:
            # êµ­ê¸° ì´ëª¨ì§€ ì¶”ì¶œ (ì˜ˆ: "eng ENG" -> "ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿")
            df['nationality'] = df['nationality'].str.split().str[0]

        if 'age' in df.columns:
            df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(0).astype(int)

        # ë“±ë²ˆí˜¸ ì¶”ê°€ (ì—†ìœ¼ë©´ ìˆœì„œëŒ€ë¡œ)
        if 'number' not in df.columns:
            df['number'] = range(1, len(df) + 1)

        df['team'] = team_name

        return df.dropna(subset=['name'])

    def _get_dummy_squad(self, team_name):
        """ë”ë¯¸ ì„ ìˆ˜ëª…ë‹¨ ë°ì´í„°"""
        # squad_data.pyì—ì„œ ê°€ì ¸ì˜¤ê¸°
        try:
            from data.squad_data import get_squad
            squad = get_squad(team_name)
            if squad:
                return pd.DataFrame(squad)
        except:
            pass

        # ì™„ì „ ë”ë¯¸ ë°ì´í„°
        return pd.DataFrame({
            'name': [f'Player {i}' for i in range(1, 16)],
            'position': ['GK', 'CB', 'CB', 'CB', 'FB', 'FB', 'DM', 'DM', 'AM', 'AM', 'W', 'W', 'W', 'ST', 'ST'],
            'age': [25] * 15,
            'number': range(1, 16),
            'nationality': ['ğŸ´'] * 15,
            'team': [team_name] * 15
        })


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    scraper = FBrefScraper()

    print("=== EPL Fixtures ===")
    fixtures = scraper.get_epl_fixtures()
    print(fixtures.head())

    print("\n=== Team Stats ===")
    stats = scraper.get_team_stats()
    print(stats.head())

    print("\n=== League Standings ===")
    standings = scraper.get_league_standings()
    print(standings.head(10))

    print("\n=== Team Squad (Manchester City) ===")
    squad = scraper.get_team_squad('Manchester City')
    print(squad.head(10))
