# Architecture Improvement Analysis
## Performance Optimization Evaluation & Recommendations

**Date**: 2025-10-16
**Status**: Analysis & Recommendation

---

## I. ì œì•ˆëœ ê°œì„ ì•ˆ ë¶„ì„: Phase ë³‘ë ¬í™”

### 1.1 ì œì•ˆ ìš”ì•½

**í•µì‹¬ ì•„ì´ë””ì–´**: Phase 2 (Statistical Engine)ì™€ Phase 3 (AI Analysis)ë¥¼ pipeline êµ¬ì¡°ë¡œ ë³‘ë ¬ ì‹¤í–‰

**ì˜ˆìƒ íš¨ê³¼**: 109s â†’ 105s (3.7% ê°œì„ )

### 1.2 ê¸°ìˆ ì  ê²€í† 

#### âœ… ì¥ì 

1. **ì´ë¡ ì  íƒ€ë‹¹ì„±**: Critical Path Method ì ìš©
2. **ìì› í™œìš©**: CPU-bound (Phase 2) vs IO-bound (Phase 3)
3. **ê¸°ìˆ  ìŠ¤íƒ**: AsyncIO íŒ¨í„´ ì‚¬ìš© ê°€ëŠ¥

#### âš ï¸  ë¬¸ì œì 

**Problem 1: ì˜ì¡´ì„± ì²´ì¸ (Dependency Chain)**

```
Iteration 1:
  Phase 2-1 (result_1) â†’ Phase 3-1 (analysis_1) â†’ adjusted_scenario_1

Iteration 2:
  Phase 2-2 (needs adjusted_scenario_1) â†’ Phase 3-2 (analysis_2)
```

Phase 3ëŠ” **ë™ì¼ iterationì˜ Phase 2 ê²°ê³¼**ë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ ì§„ì •í•œ ë³‘ë ¬í™” ë¶ˆê°€ëŠ¥.

**Problem 2: ì‹¤ì œ ì‹œê°„ ë¶„ì„ ì˜¤ë¥˜**

ì œì•ˆëœ ê³„ì‚°:
```
ê°œì„ : 30s(P1) + max(2s(P2), 40s(P3)) + max(2s(P2), 35s(P3)) = 105s
```

ì‹¤ì œ ì‹¤í–‰ íë¦„:
```
í˜„ì¬ (ìˆœì°¨):
P1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (30s)
I1: P2 â–ˆ (2s) â†’ P3 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (40s)
I2: P2 â–ˆ (2s) â†’ P3 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (35s)
P7: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (25s)
Total: 30 + 2 + 40 + 2 + 35 + 25 = 134s

ì œì•ˆ (pipeline):
P1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (30s)
I1: P2 â–ˆ (2s) â†’ P3 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (40s)
I2: P2 â–ˆ (2s ë™ì•ˆ ëŒ€ê¸°) â†’ P3 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (35s)
    â†‘ P3-1ì´ ëë‚˜ì•¼ adjusted_scenario ë°›ì„ ìˆ˜ ìˆìŒ
P7: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (25s)
Total: 30 + 2 + 40 + 2 + 35 + 25 = 134s (ë™ì¼!)
```

**ê²°ë¡ **: Phase 3ëŠ” Phase 2 ê²°ê³¼ì— ì˜ì¡´í•˜ë¯€ë¡œ ì‹¤ì œ ë³‘ë ¬í™” íš¨ê³¼ **ì—†ìŒ**.

**Problem 3: ë³µì¡ë„ ì¦ê°€ vs íš¨ê³¼**

- ì½”ë“œ ë³µì¡ë„: +40% (AsyncIO, ThreadPoolExecutor, task management)
- ìœ ì§€ë³´ìˆ˜ ë¹„ìš©: +30%
- ì‹¤ì œ ì„±ëŠ¥ ê°œì„ : **0%**
- **ROI: ë§¤ìš° ë‚®ìŒ**

---

## II. íš¨ê³¼ì ì¸ ê°œì„  ë°©ì•ˆ

### 2.1 High-Impact ê°œì„ ì•ˆ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)

#### Option 1: AI Provider ì „í™˜ â­â­â­â­â­

**í˜„ì¬**:
```
Qwen 2.5 14B (Local):
- Phase 1: ~30s
- Phase 3 (x2): ~75s
- Phase 7: ~25s
- AI Total: ~130s
- Simulation Total: ~177s (3ë¶„)
```

**ê°œì„ **:
```
Claude 3.5 Sonnet (API):
- Phase 1: ~5s
- Phase 3 (x2): ~10s
- Phase 7: ~5s
- AI Total: ~20s
- Simulation Total: ~27s (30ì´ˆ)

ê°œì„ ìœ¨: 85% ê°ì†Œ (6.5ë°° ë¹ ë¦„) ğŸš€
ë¹„ìš©: ~$0.50/simulation
```

**êµ¬í˜„ ë‚œì´ë„**: â­ (ë§¤ìš° ì‰¬ì›€ - ì´ë¯¸ êµ¬í˜„ë¨)

```python
# ë‹¨ 1ì¤„ ë³€ê²½
from ai.claude_client import ClaudeClient
ai_client = ClaudeClient()  # vs QwenClient()
```

#### Option 2: Batch Simulation (ì§„ì§œ ë³‘ë ¬í™”) â­â­â­â­â­

**Use Case**: ì—¬ëŸ¬ ê²½ê¸°ë¥¼ ë™ì‹œì— ì‹œë®¬ë ˆì´ì…˜

```python
import asyncio

async def simulate_batch(matches: List[MatchInput]) -> List[Dict]:
    """ì§„ì§œ ë³‘ë ¬ ì‹¤í–‰ - ê²½ê¸°ë“¤ì´ ë…ë¦½ì """

    # ê° ê²½ê¸°ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
    tasks = [
        asyncio.create_task(simulator.simulate_match_async(match))
        for match in matches
    ]

    results = await asyncio.gather(*tasks)
    return results

# ì‚¬ìš© ì˜ˆì‹œ
matches = [
    create_match("Arsenal", "Liverpool"),
    create_match("Man City", "Chelsea"),
    create_match("Tottenham", "Man United"),
]

# ìˆœì°¨ ì‹¤í–‰: 3 x 3ë¶„ = 9ë¶„
# ë³‘ë ¬ ì‹¤í–‰: ~3ë¶„ (API rate limit ê³ ë ¤ ì‹œ ~4ë¶„)
# ê°œì„ : 55% ì‹œê°„ ë‹¨ì¶•
```

**íš¨ê³¼**:
- 10ê²½ê¸° ì‹œë®¬ë ˆì´ì…˜: 30ë¶„ â†’ 5ë¶„ (Claude API)
- ì‹¤ì œ ì‚¬ìš© ì¼€ì´ìŠ¤ì—ì„œ ë§¤ìš° ìœ ìš©

**êµ¬í˜„ ë‚œì´ë„**: â­â­ (ì¤‘ê°„)

#### Option 3: Early Stopping with Dynamic Convergence â­â­â­â­

**í˜„ì¬ ë¬¸ì œ**: `max_iterations=2` ê³ ì •

**ê°œì„ **:
```python
class ConvergenceJudge:
    def should_stop_early(
        self,
        convergence_score: float,
        iteration: int,
        score_stability: float
    ) -> bool:
        """
        ë™ì  ì¡°ê¸° ì¢…ë£Œ íŒë‹¨

        Args:
            convergence_score: í˜„ì¬ ìˆ˜ë ´ ì ìˆ˜ (0-1)
            iteration: í˜„ì¬ iteration
            score_stability: ìµœê·¼ 2 iterationì˜ ì ìˆ˜ ë³€í™”ìœ¨
        """

        # ë†’ì€ ìˆ˜ë ´ + ì•ˆì •ì  â†’ ì¡°ê¸° ì¢…ë£Œ
        if convergence_score >= 0.8 and score_stability < 0.05:
            return True

        # 3 iteration ì´ìƒì´ê³  ì ìˆ˜ê°€ ì •ì²´ â†’ ì¡°ê¸° ì¢…ë£Œ
        if iteration >= 3 and score_stability < 0.02:
            return True

        return False
```

**íš¨ê³¼**:
- ëª…í™•í•œ ì „ë ¥ ì°¨ì´ ê²½ê¸°: 1 iterationìœ¼ë¡œ ì¢…ë£Œ â†’ 50% ë‹¨ì¶•
- í‰ê·  iteration ìˆ˜: 2.5 â†’ 1.8
- **í‰ê·  20-30% ì†ë„ í–¥ìƒ**

**êµ¬í˜„ ë‚œì´ë„**: â­â­ (ì‰¬ì›€)

---

### 2.2 Medium-Impact ê°œì„ ì•ˆ

#### Option 4: Prompt Optimization â­â­â­

**í˜„ì¬ ë¬¸ì œ**: Phase 1 í”„ë¡¬í”„íŠ¸ì— few-shot ì˜ˆì œ í¬í•¨ (ì„ íƒì )

```python
# í˜„ì¬ (include_examples=True)
EXAMPLES = """
ì˜ˆì‹œ 1: (500 tokens)
ì˜ˆì‹œ 2: (500 tokens)
"""
# Total input: ~2000 tokens

# ê°œì„  (include_examples=False)
# Total input: ~1000 tokens
```

**íš¨ê³¼**:
- Input tokens: 50% ê°ì†Œ
- AI ì²˜ë¦¬ ì‹œê°„: 10-15% ê°ì†Œ
- API ë¹„ìš©: 30% ì ˆê°

**êµ¬í˜„**:
```python
# ai/prompts/phase1_scenario.py
system_prompt, user_prompt = generate_phase1_prompt(
    match_input,
    include_examples=False  # Productionì—ì„œëŠ” False
)
```

#### Option 5: Domain Data Caching â­â­â­

**í˜„ì¬**: ë§¤ë²ˆ JSON íŒŒì¼ ì½ê¸°

```python
# ê°œì„ 
from functools import lru_cache

@lru_cache(maxsize=128)
def load_team_domain_data(team_name: str) -> TeamDomainData:
    """ìºì‹±ëœ domain ë°ì´í„° ë¡œë“œ"""
    loader = get_domain_data_loader()
    return loader.load_all(team_name)
```

**íš¨ê³¼**:
- ë°˜ë³µ ì‹œë®¬ë ˆì´ì…˜ ì‹œ I/O ì œê±°
- ~10-20ms ì ˆê° (ë¯¸ë¯¸í•˜ì§€ë§Œ í™•ì‹¤í•¨)

#### Option 6: Result Pooling & Reuse â­â­

**ì•„ì´ë””ì–´**: ë™ì¼í•œ íŒ€ ì¡°í•©ì€ ìµœê·¼ ê²°ê³¼ ì¬ì‚¬ìš© (í™•ë¥ ì  ë³€ë™ í—ˆìš©)

```python
class SimulationCache:
    def __init__(self, ttl_seconds=3600):
        self.cache = {}  # {match_key: (result, timestamp)}
        self.ttl = ttl_seconds

    def get_cached_result(
        self,
        home_team: str,
        away_team: str,
        domain_hash: str
    ) -> Optional[Dict]:
        """
        ìºì‹œëœ ê²°ê³¼ ë°˜í™˜ (1ì‹œê°„ ì´ë‚´)

        domain_hash: íŒ€ ì „ë ¥ ë³€ê²½ ê°ì§€ìš©
        """
        key = f"{home_team}_{away_team}_{domain_hash}"

        if key in self.cache:
            result, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                # ì•½ê°„ì˜ randomness ì¶”ê°€í•˜ì—¬ ë‹¤ì–‘ì„± ìœ ì§€
                return self._add_noise(result)

        return None
```

**íš¨ê³¼**:
- ë°˜ë³µ í…ŒìŠ¤íŠ¸ ì‹œ 100% ì‹œê°„ ì ˆê°
- Productionì—ì„œëŠ” ì‹ ì¤‘íˆ ì‚¬ìš© (stale data ìœ„í—˜)

---

### 2.3 Low-Impact ê°œì„ ì•ˆ

#### Option 7: Statistical Engine Vectorization â­

**í˜„ì¬**: Python loop ê¸°ë°˜

```python
# í˜„ì¬
for minute in range(90):
    for team in ['home', 'away']:
        prob = calculate_probability(...)
        if random.random() < prob:
            events.append(...)
```

**ê°œì„ **: NumPy vectorization

```python
import numpy as np

# ê°œì„ 
home_probs = np.array([calculate_prob(m, 'home') for m in range(90)])
home_events = np.random.random(90) < home_probs
```

**íš¨ê³¼**:
- Phase 2 ì†ë„: 2s â†’ 1.5s (25% ê°œì„ )
- ì „ì²´ ì˜í–¥: ~0.5s (0.3%)

**ROI**: ë‚®ìŒ (Phase 2ê°€ ì´ë¯¸ ì¶©ë¶„íˆ ë¹ ë¦„)

---

## III. ê¶Œì¥ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: Quick Wins (1-2ì£¼)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Early Stopping (Option 3)                           â”‚
â”‚    êµ¬í˜„: 2ì¼ | íš¨ê³¼: 20-30% ì†ë„ í–¥ìƒ                   â”‚
â”‚                                                         â”‚
â”‚ 2. Prompt Optimization (Option 4)                      â”‚
â”‚    êµ¬í˜„: 1ì¼ | íš¨ê³¼: 10-15% ì†ë„ í–¥ìƒ, 30% ë¹„ìš© ì ˆê°   â”‚
â”‚                                                         â”‚
â”‚ 3. Domain Data Caching (Option 5)                      â”‚
â”‚    êµ¬í˜„: 1ì¼ | íš¨ê³¼: 10-20ms ì ˆê°                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ì´ íš¨ê³¼: ~35-50% ì†ë„ í–¥ìƒ
```

### Phase 2: Major Upgrade (1ê°œì›”)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Batch Simulation (Option 2)                         â”‚
â”‚    êµ¬í˜„: 1ì£¼ | íš¨ê³¼: ë‹¤ì¤‘ ê²½ê¸° ì‹œ 50%+ ê°œì„             â”‚
â”‚                                                         â”‚
â”‚ 5. AI Provider Toggle (ì´ë¯¸ êµ¬í˜„ë¨)                    â”‚
â”‚    ì‚¬ìš©: ì¦‰ì‹œ | íš¨ê³¼: 85% ì†ë„ í–¥ìƒ (Qwenâ†’Claude)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ì´ íš¨ê³¼: Productionì—ì„œ 6ë°° ì´ìƒ ë¹ ë¦„
```

### Phase 3: Advanced Optimization (2-3ê°œì›”)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. ML-based Convergence Prediction                     â”‚
â”‚    ì•„ì´ë””ì–´: ê³¼ê±° ìˆ˜ë ´ íŒ¨í„´ í•™ìŠµí•˜ì—¬ iteration ìˆ˜ ì˜ˆì¸¡  â”‚
â”‚                                                         â”‚
â”‚ 7. GPU-accelerated Statistical Engine                  â”‚
â”‚    íš¨ê³¼: Phase 2ë¥¼ 2s â†’ 0.2s (GPU ì‚¬ìš© ì‹œ)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ì´ íš¨ê³¼: ì—°êµ¬ ë‹¨ê³„ (ì¥ê¸° roadmap)
```

---

## IV. êµ¬í˜„ ê³„íš

### 4.1 Option 3: Early Stopping êµ¬í˜„

**íŒŒì¼**: `simulation/v3/convergence_judge.py`

```python
class ConvergenceJudge:
    def __init__(
        self,
        convergence_threshold: float = 0.7,
        max_iterations: int = 5,
        early_stop_threshold: float = 0.85,  # NEW
        stability_window: int = 2  # NEW
    ):
        self.convergence_threshold = convergence_threshold
        self.max_iterations = max_iterations
        self.early_stop_threshold = early_stop_threshold
        self.stability_window = stability_window

        self.score_history = []  # Track convergence scores

    def evaluate_convergence(
        self,
        scenario: MatchScenario,
        result: SimulationResult,
        analysis: AnalysisResult,
        iteration: int
    ) -> ConvergenceInfo:
        """ê¸°ì¡´ ë¡œì§ + early stopping ì¶”ê°€"""

        # ê¸°ì¡´ ìˆ˜ë ´ ì ìˆ˜ ê³„ì‚°
        weighted_score = self._calculate_weighted_score(...)

        # ì ìˆ˜ íˆìŠ¤í† ë¦¬ ì €ì¥
        self.score_history.append(weighted_score)

        # Early stopping ì²´í¬
        should_stop_early = self._check_early_stop(
            weighted_score,
            iteration
        )

        is_converged = (
            weighted_score >= self.convergence_threshold or
            should_stop_early
        )

        return ConvergenceInfo(
            is_converged=is_converged,
            weighted_score=weighted_score,
            early_stopped=should_stop_early,  # NEW
            metrics={...}
        )

    def _check_early_stop(
        self,
        current_score: float,
        iteration: int
    ) -> bool:
        """Early stopping ì¡°ê±´ ì²´í¬"""

        # ì¡°ê±´ 1: ë§¤ìš° ë†’ì€ ìˆ˜ë ´ ì ìˆ˜
        if current_score >= self.early_stop_threshold:
            logger.info(f"Early stop: High convergence ({current_score:.2f})")
            return True

        # ì¡°ê±´ 2: ì ìˆ˜ ì•ˆì •í™” (ìµœê·¼ ë³€í™”ìœ¨ < 2%)
        if len(self.score_history) >= self.stability_window:
            recent_scores = self.score_history[-self.stability_window:]
            score_variance = np.std(recent_scores)

            if score_variance < 0.02 and iteration >= 2:
                logger.info(f"Early stop: Score stabilized (var={score_variance:.4f})")
                return True

        # ì¡°ê±´ 3: AIê°€ 'converged' ìƒíƒœ + í•©ë¦¬ì  ì ìˆ˜
        if (analysis.state == 'converged' and
            current_score >= 0.6 and
            iteration >= 2):
            logger.info(f"Early stop: AI converged with reasonable score")
            return True

        return False
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:

```python
# test_early_stopping.py
def test_early_stop_high_convergence():
    """ë§¤ìš° ë†’ì€ ìˆ˜ë ´ ì ìˆ˜ì—ì„œ ì¡°ê¸° ì¢…ë£Œ"""
    judge = ConvergenceJudge(early_stop_threshold=0.85)

    # Iteration 1ì—ì„œ 0.9 ë‹¬ì„±
    convergence = judge.evaluate_convergence(
        scenario, result, analysis, iteration=1
    )

    assert convergence.is_converged == True
    assert convergence.early_stopped == True

def test_early_stop_score_stabilization():
    """ì ìˆ˜ ì•ˆì •í™”ë¡œ ì¡°ê¸° ì¢…ë£Œ"""
    judge = ConvergenceJudge()

    # Iteration 1: 0.65
    # Iteration 2: 0.66
    # Iteration 3: 0.65 â†’ ë³€í™”ìœ¨ < 2%

    convergence = judge.evaluate_convergence(..., iteration=3)

    assert convergence.early_stopped == True
```

### 4.2 Option 4: Prompt Optimization

```python
# ai/prompts/phase1_scenario.py

def generate_phase1_prompt(
    match_input: MatchInput,
    include_examples: bool = False,  # Default to False in production
    include_detailed_instructions: bool = True
) -> Tuple[str, str]:
    """
    Generate Phase 1 prompt with optimization options.

    Args:
        match_input: Match data
        include_examples: Include few-shot examples (development only)
        include_detailed_instructions: Include verbose instructions

    Returns:
        (system_prompt, user_prompt)
    """

    # Minimal system prompt
    system_prompt = """You are a football match analyst.
Generate realistic match scenarios in JSON format."""

    # User prompt with essential data only
    match_dict = match_input.to_dict()

    user_prompt_parts = [
        f"Match: {match_dict['home_team']['name']} vs {match_dict['away_team']['name']}",
        "",
        "# Team Data",
        _format_team_data(match_dict['home_team']),
        _format_team_data(match_dict['away_team']),
    ]

    if include_detailed_instructions:
        user_prompt_parts.append(_get_detailed_instructions())
    else:
        user_prompt_parts.append(_get_minimal_instructions())

    if include_examples:
        user_prompt_parts.append(_get_examples())

    user_prompt = "\n".join(user_prompt_parts)

    return system_prompt, user_prompt

def _get_minimal_instructions() -> str:
    """Minimal instructions for faster processing"""
    return """
Generate 5-8 key events in JSON:
{
  "events": [
    {
      "minute_range": [10, 20],
      "event_type": "goal_opportunity",
      "team": "home",
      "description": "...",
      "probability_boost": 0.15
    }
  ],
  "description": "..."
}
"""
```

**ì˜ˆìƒ í† í° ì ˆê°**:
```
í˜„ì¬: ~2000 input tokens
ê°œì„ : ~1000 input tokens (50% ê°ì†Œ)

Claude API ë¹„ìš©:
- Input: $3/MTok â†’ $0.006 â†’ $0.003 (50% ì ˆê°)
- Output: ë™ì¼
- ì´ ë¹„ìš© ì ˆê°: ~30%
```

---

## V. ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì˜ˆì¸¡

### í˜„ì¬ Baseline (Qwen 2.5 14B)

```
Phase 1: 30s
Phase 2: 2s
Phase 3 (Iter 1): 40s
Phase 2: 2s
Phase 3 (Iter 2): 35s
Phase 7: 25s
Total: 134s
```

### Option 1: Claude APIë§Œ ì ìš©

```
Phase 1: 5s    (-83%)
Phase 2: 2s
Phase 3 (Iter 1): 5s    (-88%)
Phase 2: 2s
Phase 3 (Iter 2): 5s    (-86%)
Phase 7: 5s    (-80%)
Total: 24s    (-82%)
```

### Option 3 + 4: Early Stopping + Prompt Optimization

```
Phase 1: 25s    (Qwen, optimized prompt)
Phase 2: 2s
Phase 3 (Iter 1): 30s
[Early stop - convergence achieved]
Phase 7: 20s
Total: 77s    (-43%)
```

### Option 1 + 3 + 4: All Combined

```
Phase 1: 4s    (Claude, optimized)
Phase 2: 2s
Phase 3: 4s
[Early stop]
Phase 7: 4s
Total: 14s    (-90%)
```

---

## VI. ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### 6.1 ì œì•ˆëœ Pipeline ë³‘ë ¬í™”ì— ëŒ€í•œ íŒë‹¨

**ê²°ë¡ **: âŒ **êµ¬í˜„í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ê¶Œì¥**

**ì´ìœ **:
1. ì‹¤ì œ ì„±ëŠ¥ ê°œì„ : **0%** (ì˜ì¡´ì„± ì²´ì¸ ë•Œë¬¸)
2. ì½”ë“œ ë³µì¡ë„: +40%
3. ìœ ì§€ë³´ìˆ˜ ë¹„ìš©: +30%
4. ROI: ë§¤ìš° ë‚®ìŒ

### 6.2 ëŒ€ì•ˆìœ¼ë¡œ ê¶Œì¥í•˜ëŠ” ê°œì„ ì•ˆ

**ì¦‰ì‹œ ì ìš© ê°€ëŠ¥** (êµ¬í˜„ ì—†ì´):
- âœ… **Claude API ì‚¬ìš©** (85% ì†ë„ í–¥ìƒ)
  - ì½”ë“œ ë³€ê²½: 1ì¤„
  - ë¹„ìš©: ~$0.50/simulation

**1ì£¼ ë‚´ êµ¬í˜„ ê¶Œì¥**:
- âœ… **Early Stopping** (20-30% ì¶”ê°€ í–¥ìƒ)
- âœ… **Prompt Optimization** (10-15% ì¶”ê°€ í–¥ìƒ, 30% ë¹„ìš© ì ˆê°)

**ì¥ê¸° ê°œì„ **:
- âœ… **Batch Simulation** (ë‹¤ì¤‘ ê²½ê¸° ì²˜ë¦¬ ì‹œ í•„ìˆ˜)
- âœ… **ML-based Convergence Prediction** (ì—°êµ¬ ê³¼ì œ)

### 6.3 ìµœì¢… ê¶Œì¥ ìŠ¤íƒ

```python
# Production Configuration
simulator = MatchSimulatorV3(
    statistical_engine=StatisticalMatchEngine(seed=None),  # Random seed
    ai_integration=AIIntegrationLayer(
        ai_client=ClaudeClient(),  # Claude API
        provider='claude'
    ),
    convergence_judge=ConvergenceJudge(
        convergence_threshold=0.7,
        max_iterations=5,
        early_stop_threshold=0.85  # NEW
    ),
    max_iterations=5  # Allow more but stop early if converged
)

# Prompt configuration
system_prompt, user_prompt = generate_phase1_prompt(
    match_input,
    include_examples=False,  # Optimized
    include_detailed_instructions=False  # Minimal
)
```

**ì˜ˆìƒ ì„±ëŠ¥**:
- í‰ê·  ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„: **15-20ì´ˆ** (í˜„ì¬ 177ì´ˆ ëŒ€ë¹„ 88% ê°œì„ )
- í‰ê·  ë¹„ìš©: $0.30-0.50
- í’ˆì§ˆ: ë™ì¼ ë˜ëŠ” ë” ìš°ìˆ˜ (Claude > Qwen 14B)

---

**END OF ANALYSIS**
